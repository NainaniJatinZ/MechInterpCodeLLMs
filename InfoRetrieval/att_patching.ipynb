{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4cadc4-b5c3-4c99-8a08-c32570afd546",
   "metadata": {},
   "outputs": [],
   "source": [
    "PYTORCH_CUDA_ALLOC_CONF=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a3f796-9f4a-44e9-b900-fcb4a44186d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformer_lens in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (1.17.0)\n",
      "Requirement already satisfied: numpy>=1.24 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformer_lens) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformer_lens) (4.10.0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformer_lens) (4.65.0)\n",
      "Requirement already satisfied: accelerate>=0.23.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformer_lens) (0.28.0)\n",
      "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformer_lens) (0.14.1)\n",
      "Requirement already satisfied: einops>=0.6.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformer_lens) (0.6.1)\n",
      "Requirement already satisfied: jaxtyping>=0.2.11 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformer_lens) (0.2.28)\n",
      "Requirement already satisfied: rich>=12.6.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformer_lens) (13.7.1)\n",
      "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformer_lens) (0.0.3)\n",
      "Requirement already satisfied: wandb>=0.13.5 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformer_lens) (0.16.6)\n",
      "Requirement already satisfied: datasets>=2.7.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformer_lens) (2.11.0)\n",
      "Requirement already satisfied: fancy-einsum>=0.0.3 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformer_lens) (0.0.3)\n",
      "Requirement already satisfied: sentencepiece in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformer_lens) (0.1.97)\n",
      "Requirement already satisfied: transformers>=4.37.2 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformer_lens) (4.40.1)\n",
      "Requirement already satisfied: torch>=1.10 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformer_lens) (2.2.1)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformer_lens) (2.2.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer_lens) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer_lens) (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer_lens) (23.1)\n",
      "Requirement already satisfied: pyyaml in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer_lens) (6.0.1)\n",
      "Requirement already satisfied: psutil in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer_lens) (5.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from datasets>=2.7.1->transformer_lens) (3.9.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from datasets>=2.7.1->transformer_lens) (15.0.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from datasets>=2.7.1->transformer_lens) (2.31.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from datasets>=2.7.1->transformer_lens) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from datasets>=2.7.1->transformer_lens) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from datasets>=2.7.1->transformer_lens) (0.70.14)\n",
      "Requirement already satisfied: responses<0.19 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from datasets>=2.7.1->transformer_lens) (0.18.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from datasets>=2.7.1->transformer_lens) (2024.3.1)\n",
      "Requirement already satisfied: typeguard==2.13.3 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from jaxtyping>=0.2.11->transformer_lens) (2.13.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from pandas>=1.1.5->transformer_lens) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from pandas>=1.1.5->transformer_lens) (2024.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from rich>=12.6.0->transformer_lens) (2.15.1)\n",
      "Requirement already satisfied: sympy in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.10->transformer_lens) (1.11.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.10->transformer_lens) (12.1.105)\n",
      "Requirement already satisfied: networkx in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.10->transformer_lens) (3.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.10->transformer_lens) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.10->transformer_lens) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.10->transformer_lens) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.10->transformer_lens) (2.19.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.10->transformer_lens) (10.3.2.106)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.10->transformer_lens) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.10->transformer_lens) (12.1.105)\n",
      "Requirement already satisfied: filelock in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.10->transformer_lens) (3.9.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.10->transformer_lens) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.10->transformer_lens) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.10->transformer_lens) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.10->transformer_lens) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.10->transformer_lens) (3.1.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10->transformer_lens) (12.4.99)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformers>=4.37.2->transformer_lens) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from transformers>=4.37.2->transformer_lens) (0.19.1)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from wandb>=0.13.5->transformer_lens) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from wandb>=0.13.5->transformer_lens) (4.25.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from wandb>=0.13.5->transformer_lens) (68.0.0)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from wandb>=0.13.5->transformer_lens) (3.1.43)\n",
      "Requirement already satisfied: setproctitle in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from wandb>=0.13.5->transformer_lens) (1.3.3)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from wandb>=0.13.5->transformer_lens) (8.1.7)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from wandb>=0.13.5->transformer_lens) (2.0.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.11)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (1.26.18)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from jinja2->torch>=1.10->transformer_lens) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from sympy->torch>=1.10->transformer_lens) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformer_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7030d0-bd8f-4892-8825-7be2950e64db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtyping in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (0.1.4)\n",
      "Requirement already satisfied: torch>=1.7.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torchtyping) (2.2.1)\n",
      "Requirement already satisfied: typeguard>=2.11.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torchtyping) (2.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (4.10.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (8.9.2.26)\n",
      "Requirement already satisfied: filelock in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (3.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (12.1.105)\n",
      "Requirement already satisfied: sympy in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (3.1.2)\n",
      "Requirement already satisfied: networkx in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (2.19.3)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (2.2.0)\n",
      "Requirement already satisfied: fsspec in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from torch>=1.7.0->torchtyping) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->torchtyping) (12.4.99)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from jinja2->torch>=1.7.0->torchtyping) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from sympy->torch>=1.7.0->torchtyping) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5529c7b2-c915-4570-9212-81abf8c11b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "# Import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.notebook as tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtyping import TensorType as TT\n",
    "from typing import List, Union, Optional, Callable\n",
    "from functools import partial\n",
    "import copy\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML, Markdown\n",
    "\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "\n",
    "from neel_plotly import line, imshow, scatter\n",
    "import transformer_lens.patching as patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1adefec-cd20-4973-a3a8-0212fc81e345",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bac962-31c9-4b9c-a128-2dc6bf5d35d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login --token \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41abf9f3-9d6b-4d04-ae37-a5ce94a579be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85da577-bf0e-474a-af0a-dc1a2e8ad2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b89e19-c814-4dfc-b3b9-fa239cc0bf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for jnainani_umass_edu: "
     ]
    }
   ],
   "source": [
    "!sudo kill -9 333984 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bbb4ca-63fc-40f9-93a5-c9297f86985b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26f7b9f-81bf-40a6-8569-fb43a93f5a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa87a833-d833-409a-8e76-aa51668285c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298d418185134ff08ba8869bde9ecccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 79.15 GiB of which 32.12 MiB is free. Process 333984 has 61.71 GiB memory in use. Including non-PyTorch memory, this process has 17.40 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 17.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mHookedTransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta-llama/Llama-2-7b-hf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/finetuning/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:1295\u001b[0m, in \u001b[0;36mHookedTransformer.from_pretrained\u001b[0;34m(cls, model_name, fold_ln, center_writing_weights, center_unembed, refactor_factored_attn_matrices, checkpoint_index, checkpoint_value, hf_model, device, n_devices, tokenizer, move_to_device, fold_value_biases, default_prepend_bos, default_padding_side, dtype, **from_pretrained_kwargs)\u001b[0m\n\u001b[1;32m   1285\u001b[0m model\u001b[38;5;241m.\u001b[39mload_and_process_state_dict(\n\u001b[1;32m   1286\u001b[0m     state_dict,\n\u001b[1;32m   1287\u001b[0m     fold_ln\u001b[38;5;241m=\u001b[39mfold_ln,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     refactor_factored_attn_matrices\u001b[38;5;241m=\u001b[39mrefactor_factored_attn_matrices,\n\u001b[1;32m   1292\u001b[0m )\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m move_to_device:\n\u001b[0;32m-> 1295\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove_model_modules_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded pretrained model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into HookedTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.conda/envs/finetuning/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:1036\u001b[0m, in \u001b[0;36mHookedTransformer.move_model_modules_to_device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munembed\u001b[38;5;241m.\u001b[39mto(devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mn_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg))\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[0;32m-> 1036\u001b[0m     \u001b[43mblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_for_block_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/finetuning/lib/python3.10/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/finetuning/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/finetuning/lib/python3.10/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.conda/envs/finetuning/lib/python3.10/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 79.15 GiB of which 32.12 MiB is free. Process 333984 has 61.71 GiB memory in use. Including non-PyTorch memory, this process has 17.40 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 17.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "model = HookedTransformer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", device=device)\n",
    "\n",
    "# device = torch\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ff004b-d5d3-405e-a682-675bb5adc1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_use_attn_result(True)\n",
    "model.set_use_attn_in(True)\n",
    "model.set_use_hook_mlp_in(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a050eb8-01d6-40b3-a548-adbf3d95b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"When John and Mary went to the shops, John gave the bag to \",\n",
    "    \"When John and Mary went to the shops, Mary gave the bag to \",\n",
    "    \"When Tom and James went to the park, James gave the ball to \",\n",
    "    \"When Tom and James went to the park, Tom gave the ball to \",\n",
    "    \"When Dan and Sid went to the shops, Sid gave an apple to \",\n",
    "    \"When Dan and Sid went to the shops, Dan gave an apple to \",\n",
    "    \"After Martin and Amy went to the park, Amy gave a drink to \",\n",
    "    \"After Martin and Amy went to the park, Martin gave a drink to \",\n",
    "]\n",
    "answers = [\n",
    "    (\"Mary\", \"John\"),\n",
    "    (\"John\", \"Mary\"),\n",
    "    (\"Tom\", \"James\"),\n",
    "    (\"James\", \"Tom\"),\n",
    "    (\"Dan\", \"Sid\"),\n",
    "    (\"Sid\", \"Dan\"),\n",
    "    (\"Martin\", \"Amy\"),\n",
    "    (\"Amy\", \"Martin\"),\n",
    "]\n",
    "\n",
    "clean_tokens = model.to_tokens(prompts)\n",
    "# Swap each adjacent pair, with a hacky list comprehension\n",
    "corrupted_tokens = clean_tokens[\n",
    "    [(i + 1 if i % 2 == 0 else i - 1) for i in range(len(clean_tokens))]\n",
    "]\n",
    "print(\"Clean string 0\", model.to_string(clean_tokens[0]))\n",
    "print(\"Corrupted string 0\", model.to_string(corrupted_tokens[0]))\n",
    "\n",
    "answer_token_indices = torch.tensor(\n",
    "    [\n",
    "        [model.to_single_token(answers[i][j]) for j in range(2)]\n",
    "        for i in range(len(answers))\n",
    "    ],\n",
    "    device=model.cfg.device,\n",
    ")\n",
    "print(\"Answer token indices\", answer_token_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f3a45-034d-4072-a2ca-9f6a9ab1a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logit_diff(logits, answer_token_indices=answer_token_indices):\n",
    "    if len(logits.shape) == 3:\n",
    "        # Get final logits only\n",
    "        logits = logits[:, -1, :]\n",
    "    correct_logits = logits.gather(1, answer_token_indices[:, 0].unsqueeze(1))\n",
    "    incorrect_logits = logits.gather(1, answer_token_indices[:, 1].unsqueeze(1))\n",
    "    return (correct_logits - incorrect_logits).mean()\n",
    "\n",
    "\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "\n",
    "clean_logit_diff = get_logit_diff(clean_logits, answer_token_indices).item()\n",
    "print(f\"Clean logit diff: {clean_logit_diff:.4f}\")\n",
    "\n",
    "corrupted_logit_diff = get_logit_diff(corrupted_logits, answer_token_indices).item()\n",
    "print(f\"Corrupted logit diff: {corrupted_logit_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127b65a2-20e1-4399-a731-8d9318c458ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_BASELINE = clean_logit_diff\n",
    "CORRUPTED_BASELINE = corrupted_logit_diff\n",
    "\n",
    "def ioi_metric(logits, answer_token_indices=answer_token_indices):\n",
    "    return (get_logit_diff(logits, answer_token_indices) - CORRUPTED_BASELINE) / (\n",
    "        CLEAN_BASELINE - CORRUPTED_BASELINE\n",
    "    )\n",
    "\n",
    "print(f\"Clean Baseline is 1: {ioi_metric(clean_logits).item():.4f}\")\n",
    "print(f\"Corrupted Baseline is 0: {ioi_metric(corrupted_logits).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bd8c7eb-61c0-4c02-bec8-430da33f0def",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m\n\u001b[1;32m     25\u001b[0m     model\u001b[38;5;241m.\u001b[39mreset_hooks()\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m         value\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m     28\u001b[0m         ActivationCache(cache, model),\n\u001b[1;32m     29\u001b[0m         ActivationCache(grad_cache, model),\n\u001b[1;32m     30\u001b[0m     )\n\u001b[1;32m     33\u001b[0m clean_value, clean_cache, clean_grad_cache \u001b[38;5;241m=\u001b[39m get_cache_fwd_and_bwd(\n\u001b[0;32m---> 34\u001b[0m     \u001b[43mmodel\u001b[49m, clean_tokens, ioi_metric\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClean Value:\u001b[39m\u001b[38;5;124m\"\u001b[39m, clean_value)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClean Activations Cached:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(clean_cache))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "Metric = Callable[[TT[\"batch_and_pos_dims\", \"d_model\"]], float]\n",
    "filter_not_qkv_input = lambda name: \"_input\" not in name\n",
    "\n",
    "\n",
    "def get_cache_fwd_and_bwd(model, tokens, metric):\n",
    "    model.reset_hooks()\n",
    "    cache = {}\n",
    "\n",
    "    def forward_cache_hook(act, hook):\n",
    "        cache[hook.name] = act.detach()\n",
    "\n",
    "    model.add_hook(filter_not_qkv_input, forward_cache_hook, \"fwd\")\n",
    "\n",
    "    grad_cache = {}\n",
    "    \n",
    "    \n",
    "\n",
    "    def backward_cache_hook(act, hook):\n",
    "        grad_cache[hook.name] = act.detach()\n",
    "\n",
    "    model.add_hook(filter_not_qkv_input, backward_cache_hook, \"bwd\")\n",
    "\n",
    "    value = metric(model(tokens))\n",
    "    value.backward()\n",
    "    model.reset_hooks()\n",
    "    return (\n",
    "        value.item(),\n",
    "        ActivationCache(cache, model),\n",
    "        ActivationCache(grad_cache, model),\n",
    "    )\n",
    "\n",
    "\n",
    "clean_value, clean_cache, clean_grad_cache = get_cache_fwd_and_bwd(\n",
    "    model, clean_tokens, ioi_metric\n",
    ")\n",
    "print(\"Clean Value:\", clean_value)\n",
    "print(\"Clean Activations Cached:\", len(clean_cache))\n",
    "print(\"Clean Gradients Cached:\", len(clean_grad_cache))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e507d-456a-4597-86d1-f2345692509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_value, corrupted_cache, corrupted_grad_cache = get_cache_fwd_and_bwd(\n",
    "    model, corrupted_tokens, ioi_metric\n",
    ")\n",
    "print(\"Corrupted Value:\", corrupted_value)\n",
    "print(\"Corrupted Activations Cached:\", len(corrupted_cache))\n",
    "print(\"Corrupted Gradients Cached:\", len(corrupted_grad_cache))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-finetuning]",
   "language": "python",
   "name": "conda-env-.conda-finetuning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
